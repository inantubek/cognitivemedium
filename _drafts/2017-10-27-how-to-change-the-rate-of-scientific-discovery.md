---
layout: post
title:  "How to Greatly Increase the Rate of Scientific Discovery?"
date:   2017-10-27
permalink: /rate_of_discovery
---

By [Michael Nielsen](http://michaelnielsen.org)

Amongst scientists themselves, the most popular answer to this
question seems to be: "give us more money!"

This answer is also popular amongst the public, and I've seen it
advocated by influential journalists, politicians, and business
people.

It's true that more money, cleverly deployed based on new
organizational and methodological ideas, may be helpful for science,
perhaps even transformational.

But I believe that a recipe of "more money" on its own, without clever
new organizational and methodological ideas, is unlikely to have much
impact.

To understand why, consider a simple model.

Suppose only 50 people in the world could make a living playing
professional tennis.  Suppose then the amount of money spent on
professional tennis doubled, so it became possible to employ more
tennis players, raising the number of professionals to, say, 200,
depending on the way returns are distributed.  The extra 150 people so
employed would mostly be players who formerly wouldn't have made it,
and it seems likely there would only be a small improvement in the
quality of the world's tennis.
 
In a similar way, if we doubled spending on science, it seems likely
that much of the impact would be in employing people who currently
adjudged nearly but not quite good enough to be employed before. The
employment situation of the most outstanding scientists would not be
changed.  They might receive more money to do additional experiments,
but again, the additional experiments they do would

Of course, these are just simple models. In tennis, it makes quite a
bit of sense to rank players in linear order of ability. But in
science it is deeply erroneous to think of scientific ability in a
linearly ordered fashion. I suspect that for clever new organizational
and methodological ideas to succeed it will be _because_ they
understand this is an error. But one really does need such ideas; more
money on its own will simply run up against diminishing returns.

If we're to find such new organizational and methodological ideas,
what are they?

## Narrative excavation

In 2006 I was working in the field of quantum computing.  At the time
I was considering moving institutions, and was thinking broadly about
the kind of work I wanted to be doing.  As part of this I wrote down a
list of the ten quantum computing papers I most admired.

I was surpised by two things:

1. None of the papers on my list were grant funded, apart from generic
   undirected fellowship funding; and

2. Only one principal author was a professor at a research university
   (Richard Feynman, in fact).

This was quite an eye-opener. At the time, nearly all papers in the
field were grant funded, and had principal authors who were professors
at research universitities.

What was worse: I was grant funded, and a professor at a research
university.

Of course, this was hardly a rigorous association, but it bothered me
a lot. Might there be 

I've come to think the reasons have to do with stories.

Consider one of the papers on my list, a wonderful 1985 paper by David
Deutsch.  This paper, more than any other, really founded the field of
quantum computing.

Deutsch did the work leading to the paper from the late 1970s through
the early 1980s. It was, at the time, unfundable. A shallow analysis
would say that the reason is that grant agencies are risk averse,
won't fund bold work, and so on.

While those things may be true, they don't get to the heart of things.
That paper is really about excavating a new story of what it is to do
scientific work &ndash; a coherent, big-picture set of questions about
the world. 

At the same time, both grants are job applications are basically
stories. Deutsch, by definition, didn't have much of a story until
near the very end of that process. And so he had nothing compelling at
all to show to get a grant. He was truly un-fundable.

The situation is compounded by the fact that grants and jobs are both
political processes, with advocates and alliances, and people
(naturally) fighting for what they believe in.  Alliances, of course,
are formed around shared storesi. A new story has no natural
constituency, and so very little political power. This made Deutsch
doubly un-fundable.

The lesson, I think, is that if you want to do this kind of
foundational work, then, with apologies to Groucho: "You should never
want to do any research work you can get funded."  If you can get it
funded, that means it buys into existing narratives.

This story is a common one. 

Let me give a personal example, at the risk of seeming self-aggrandizing.

In the mid-2000s I was becoming increasingly interested in open
science.  I wasn't entirely sure what that meant &ndash; in my mind it
was an amorphous set of ideas around collective intelligence, the
political economy and norms of science, and the restructuring of
expert attention.

I talked to funders about these ideas. Most thought I was crazy. The
most positive responses were along the lines of: "Oh, you're talking
about open access (or open data)", to which I replied "No, that's
_not_ what I'm talking about".  It took five years, but I gradually
crystallized a vision of what I thought open science is about, in
forums such as Nature, TED, and the Wall Street Journal.

At the same time, many other people were similarly working on
crystallizing this story.  But it nonetheless coalesced into something
.

This wasn't
something I did alone

It took five year

interested in open science, and the idea that new tools f.  I wanted
to work



think the reasons are interesting. A shallow analysis would say that grant agencies are risk-averse, won’t fund bold work, etc.  Maybe true, but doesn’t get to the heart of things.  That paper is really about excavating a new story of what it is to do scientific work - a coherent, big-picture set of questions about the world.   Excavating a new story is hard work: it took Deutsch 5-10 years.

(I apologize for the rather strange verb choice.  “Excavation” really does seem like the right verb, though: you’re digging the story out of a background soil of human knowledge.)


When Hamming, Feynman et al defend unfashionable work, my guess is that they’re often defending people who go off and try to excavate new stories.  Their accounts focus on the fact that this is a way of doing _important_ work.  But they fail to properly acknowledge that it is also likely to mean considerable intellectual loneliness, and likely a long (possibly permanent) isolation from conventional success, and that these things are an intrinsic consequence of the process.  If you can achieve conventional success (a job, funding, maybe even prizes), that means you’re attached to an existing community, which means you’re not excavating a new story.

It’s telling, in my opinion, that both Feynman and Hamming made their reputation as young men by solving hard problems that were nonetheless part of an existing narrative.  As old men both helped pioneer new narratives, and their colleagues often had trouble understanding what the heck they were doing. 

This account is all way too simplistic. Nonetheless, I believe there is some truth to these mechanisms, and that they’re related to the problem Joe identifies above.



## Maybe science is mostly done, and we're hitting the point of diminishing returns?

One pessimistic point of view is that maybe science is mostly done,
that we've hit the point of diminishing returns, that we will invest
ever larger sums of money for ever smaller reward.

This point of view has been developed by many, perhaps most notably
the writer John Horgan in his stimulating 1996 book "The End of
Science".



I've often had dinner with quantum computing people, for them to talk
about the glory days of the 1990s, when it was easy to obtain major
results. Today, far better-informed people are working much harder to
obtain minor incremental results.

It may be that this is merely nostalgia. But let's suppose it were

The End of
Science.

Gordon.  End of Science.,

Is it Nostalgia for the past?

One tempting method of analysis is to ask subject-matter experts if
they feel that their field is slowing down or speeding up.  I've sat
through many conversations like this.

## Changing the rate at which new fields are produced

## Against grant agencies

## Risk and heterogeneity


## Maybe large parts of science are simply wrong?

## What about AI? What about intelligence augmentation?  What about open science?



In a sense, this experiment has been tried. The NIH budget rose from
400 million in 1960 to 33.1 billion in 2017, a growth rate more than 4
percent above inflation.  Over the same period, the NSF budget rose
from 153 million to 7.5 billion, a growth rate more than 3 percent
above inflation. These are remarkable rates of growth, comparable to
the fastest growing sectors of the economy.



NIH: 400 million (3.3 bill) in 1960 to 33.1 billion 2017.  More than 4% per year.

NSF: 153 million to (1268) 7.5 billion.  More than 3% per year.



+ Such a doubling has been done before.  The NIH budget doubled
  between 1998 and 2003 after a bipartisan push.  It made for a fun
  five years, but frankly seems to have had little impact on
  biomedical research. Indeed, it may even have created problems --
  institutions designed under expanding budgets are often extremely
  poorly suited to times of stasis.  Much of what scientists complain
  about as "too little funding" really means "our institutions were
  designed when we had 4% annual growth, and now we've only got 2% and
  we're suffocating".

+ The one qualitative change that more money certainly enables is very
  large scientific projects.  In some cases I think it's clearly worth
  it: LIGO, the Sloan Digital Sky Survey.  But in the majority of
  cases it's either unclear, or even doubtful, that the project was
  worth it.  You can fund a lot of small labs with one LHC-size chunk
  of money.  

ARE WE NEAR THE END?

Patrick asked if we've simply found the low-hanging fruit in a lot of
fields, and so we're hitting the point of diminishing returns.  A few
observations:

+ Things can be slowing down within every field, and yet if the rate
  of field-production is sufficiently high, things can be speeding up
  overall.  (The chip manufacturers see this.)  Concentrating on a
  per-field analysis only is a mistake.  This strongly affected the
  conversation the other night between Patrick, Scott Aaronson, Adam
  Brown, and myself.  It's a form of availability bias. 

  (Related: through most of history a large fraction of the most
  interesting work has been invisible while it was going on.  I think
  it likely that's still true.  Luke Muehlhauser said "But what about
  the internet".  I think, though, that much of what prevents
  recognition isn't lack of access, but rather that the most important
  ideas often don't fit within existing narratives, and thus are
  ignored. Smart, efficient people are particularly susceptible to
  this.)

+ Founding a field is in part a political operation: a matter of
  getting the right people installed in senior positions at the grant
  agencies, universities, etc.  This takes a generation.  There's a
  reason David Deutsch, Steven Wiesner et al didn't have jobs; indeed,
  brilliant founders of fields often live precarious lives, only
  rewarded much later, if at all, while mediocre much-later followers
  often do very well.  There's a version of the Matthew Effect at
  play: to the fields which have is given.  That's the key feedback
  dynamic which ensures that fields are either under-funded or
  over-funded.  It's also the dynamic which keeps the rate of
  field-creation very slow.  However, there's nothing inevitable about
  this arrangement; it's a mostly-accidental consequence of historical
  choices about the organization of science.  I believe fields could
  be produced (and destroyed) far more rapidly, almost on a production
  line.

+ My impression, as a non-expert, is that mathematics continues to
  enjoy an astounding golden age. My guess is that this golden age
  will get far far better in the next few decades, as AI starts to
  affect mathematics.  The world's best Go player remarked earlier
  this year that one thing they'd learned from AlphaGo is that humans
  understand almost nothing about the limits of Go.  I think we're
  about to find this with mathematics too.  This is an area where my
  instinctive feeling is that not only have we not hit diminishing
  returns, things are about to speed up dramatically.

+ I believe AI and intelligence augmentation will merge into a new
  field over the next few decades.  AIs will develop new human-useable
  abstractions and explanatory techniques, and we'll use those to
  understand what the AI has discovered, and to make discoveries of
  our own.  Rather than just outsourcing our cognition to AIs (which
  is more or less the conventional model), they'll actually change our
  cognition.  Not in the sense of neural interfaces (though maybe that
  too), but in the form of new primitives with which to think.
  Mathematica already does a little of this.

FAILURE QUOTAS

[The next few bits talks about how to change the risk profile of
science funding, and heterogeneity]

An idea I've pitched a few times to grant agencies: run a program
where all grants are assessed on a pass/fail basis, and the fail rate
must be kept above some relatively high threshold value, say 50%, or
even 80% for a high-risk program.  If the failure audit is failed, the
program manager's (etc) job is on the line.

People at the agencies respond in a curious way to this.  They laugh,
and often become intensely fascinated by the idea -- I've spent hours
talking with some of them.  But the idea is somehow too strange or far
out to ever be taken seriously.

(That herding, conformist, homogenizing instinct is a big problem in
science.  I talk more about this below.)


THE RISK-AVERSE SCIENTIST

I'm often surprised at how risk-averse most scientists are. They're
often smart, hard-working, sometimes narrowly imaginative.  But the
great majority are mindboggingly risk averse.

A personal example: I've been told many, many times by scientists that
it was "brave" for me to quit my notionally tenured job.  It's meant
nicely, and as a compliment, but it bothers me that those same people
take for granted the jobs done by police, fire fighters, the military,
all of which involve risks incomparably larger.  Within science I'm a
risk-taker; within society at large I'm risk-averse.

My guess is that this risk aversion is likely to be an accidental
selection effect which is a consequence of something else in the
typical scientific career path, probably something which seems quite
reasonable.  I'm not sure what.

It may be possible to short circuit this somehow.  I've noticed the
Thiel Fellows seem to have a somewhat different risk profile.  That's
perhaps due in part to the fact that they started by doing something
at least somewhat risky (TF, not University).

(On a related note, I've noticed that Israeli scientists seem at least
somewhat less risk averse.  I've wondered it this may be due to the
fact that Israel is threatened in a way that most other countries are
not.)

INSTITUTIONAL HETEROGENEITY

Science, and in particular scientific institutions, are too
homogeneous.  

Aside from scale, I believe the chief advantage the US has is relative
heterogeneity in its institutions, even adjusting for its increased
scale.  MIT, Caltech and Stanford are vastly more different from each
other than any three Australian Universities.  And the US also has
vastly more diversity in industrial and military research.

Nonetheless, US science is still depressingly homogeneous.  Mostly, I
believe, because of the destructive centralizing influence of the NIH,
NSF and similar big agencies.  The theory seems to be that if X is
good, then surely 100 times X must be even better!  But you almost
immediately hit the point of diminishing returns.

Part of this is that there's too few ways scientific institutions are
killed off.

There's also too few ways new scientific institutions are started.
("YCombinator for Research Labs"?)

And there's too little selection pressure favouring difference and
experimentation in organizational forms.

With 100 billion dollars, you could actually start YCombinator for
grant agencies, spinning off a dozen or so small agencies each year.
Most would fail.  But one or two might turn into the intellectual
equivalent of unicorns.


INSTITUTE FOR OPEN SOURCE

[Two obvious gaps in the market for research institutions]

Open source software tends to be produced in one of two ways: small
hobbyist projects, and larger projects which are primarily corporate
funded (e.g., Linux, Rails, Python, etc).  The corporate funded ones
are fine, but those projects almost invariably serve corporate ends,
and only incidentally produce new understanding in the world.

A small university costs a few hundred million dollars to boot up.
What would it look like to raise 100 million as an endowment, and then
use the interest to fund dozens of full-time Open Source Fellows, say
for anything from 3 month to 3 year terms?  There could also be a
bridging program to help the best projects find long-term support
elsewhere.  E.g., cultivate relationships with big foundations, with
companies, with not-for-profits etc, make introductions, do demo days,
and so on.

Of course, there _are_ all sorts of genuine issues with doing this
well. It could easily turn into navel gazing, or work on stuff which
could easily be done elsewhere.  But with the right CEO, and with a
good selection of audacious projects by dedicated people, I suspect it
would be transformative for tech.

A similar but broader idea is an Institute for Artifact-Based
Research.  Traditional research organizations express their research
in the form of papers.  Papers are great, but very limited.  Often the
clearest expression of an important idea or research result is in a
program, a device, a demo, an experience, an interface, a film, a
performance [etc]. Certainly, if I wanted to found a University, I'd
consider founding one based on the production of artifacts which
expand human understanding.


CAREER NETWORK EFFECTS

One tempting practical way to attack the problem of the title is to
set up new institutions which work in new ways.  If successful in
really being different, you might hope that your model would be cloned
or extended.

You see this aspiration to some extent with YC Research, Open AI,
Perimeter Institute, the Santa Fe Institute, the Media Lab, HHMI, etc.

This is worthwhile, but there's a very strong sort of regression to
the institutional mean, due to career network effects.  While your
institution may be new and different, the pipeline of people you are
drawing on still come from existing institutions, and they are likely
to want to at least have the option to go back there, which means
playing to the same evaluative norms.

This has affected Perimeter Institute very badly --- it's really just
a well-funded department for theoretical physics, despite aspirations
to be otherwise.  I suspect it's happened a little to HHMI, though
HHMI is large enough that to some extent they've transcended the
problem.

The best resolutions I know of this problem:

+ Hire people with truly unusual backgrounds. YCR / HARC hired a bunch
  of artists and tech people without PhDs.  I think that was a
  brilliant choice.  It made YCR / HARC utterly unlike anywhere else
  in the world.

+ Commit to your weirdness in your title.  The Santa Fe Institute is
  an institute for complex systems.  They've varied the title a bit
  over the years "Institute for Complexity", "Institute for Complex
  Systems" etc, but there's always some variant there.  And this is
  reflected in their hiring process: every hire is a referendum on
  what complex systems means. That's difficult and time-consuming and
  sometimes frustrating; it also means they're always developing their
  narrative, it's forcing them to be original. I think it's a
  brilliant forcing function.  I suspect the Media Lab has benefited a
  lot from this too.

  [Both SFI and the Media Lab get a bad rap.  But I think to a large
  extent that reflects jealousy, not a reasonable evaluation.  At
  their price, they've been vastly more successful than almost all
  comparable operations.]

+ Do things which are different by design.  The Aspen Center for
  Physics really changed physics, and had an outsize effect, because
  it was intended to do something different (bring physicists for
  intermediate periods of time and intense collaboration, rather than
  semi-permanently).







Ideas: narratives.  reproducibility: it's really a mechanism.  Complex
systems.  open science.  New tools.  AI.  Explainability.  Merging of
AI with IA to form what Shan Carter and I have been calling Artificial
Intelligence Augmentation.



On silver bullets: it's tempting to assume that there's a single
silver bullet that will speed up the rate of progress across all of
science. However, different parts of science work in dfiferent ways,
and different constraints may be the limiting factor.  In social
psychology, recent evidence suggests that standards of evidence have
been such that relatively little progress has been made over the past
few decades.  Without changing 

How 
+ New tools.
+ Changed social institutions.
+ New cognitive technologies.
+ AI.
 
Diminishing returns.  Much like 

MORE SOURCES AND SINKS FOR ORGANIZATIONAL FORMS

Honestly


MEASURABILITY

Patrick was very interested in measuring the rate of progress, and
seeing if diminishing returns can be quantified.

I think this would be well worth someone doing.  Even better, many
people with very different backgrounds. 

I also think it'd likely fail.

Of course, lots of people are doing this kind of thing.  There's
numerous papers about the rate of innovation, rate of new ideas, etc.
There's an entire field of scientometrics.  And many countries now
spend enormous sums of money on research assessment exercises of
various kinds.

So far as I can see, this is mostly good for generating cautionary
tails.  But maybe someone really smart and creative and insightful
might have some interesting ideas, better than "let's count citations
[etc]".  Looking at events precipitating structural changes in the
shape of knowledge seems more promising.


WHO MIGHT HAVE GOOD IDEAS ABOUT THIS?

Tyler Cowen. Robin Hanson. Baseball analytics people (Bill
James?). Alan Kay.  Bret Victor. Vi Hart. John Ioannidis.  Darius
Cuplinkas.  Melissa Hagemann.  Peter Suber.  Josh Greenberg.  Holden
Karnofsky.  Nick Beckstead.  Stewart Brand.

Most scientists have terrible ideas about this; it's possible it's
Stockholm Syndrome or something similar.  But some are
insightful. And, in any case, some would
